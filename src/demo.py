import os
import re

import chainlit as cl
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain_community.document_loaders import (
    PyMuPDFLoader, UnstructuredExcelLoader, UnstructuredWordDocumentLoader)
from langchain_community.vectorstores import FAISS
from openai import OpenAI

client = OpenAI()

settings = {
    "model": "gpt-4o",
    "temperature": 0.5,
}

file_content = ""
vector_store = None
last_user_message = ""


def vectorize_documents(documents):
    embeddings = OpenAIEmbeddings()
    texts = [doc.page_content for doc in documents]
    return FAISS.from_texts(texts, embeddings)


def search_documents(query, vector_store):
    if not isinstance(query, str):
        raise TypeError("ã‚¯ã‚¨ãƒªã¯æ–‡å­—åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
    try:
        results = vector_store.similarity_search_with_score(query)
    except Exception as e:
        raise ValueError(f"FAISSæ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    return [res[0].page_content for res in results[:3]]


def sanitize_text(text):
    text = re.sub(r'\b(role|assistant|system|user)\b\s*:\s*', '', text, flags=re.IGNORECASE)
    text = re.sub(r'<.*?>', '', text)
    return text


def create_prompt(user_message, relevant_texts):
    system_message = "ã‚ãªãŸã¯å„ªç§€ãªQAã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸæ–‡æ›¸ã®å†…å®¹ã«åŸºã¥ã„ã¦æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    assistant_message = "\n".join(relevant_texts)
    return [
        {"role": "system", "content": system_message},
        {"role": "assistant", "content": assistant_message},
        {"role": "user", "content": user_message.strip()},
    ]


async def call_openai_api(user_message, relevant_texts):
    try:
        messages = create_prompt(user_message, relevant_texts)
        response = client.chat.completions.create(
            model=settings['model'],
            messages=messages,
            temperature=settings['temperature'],
        )
        return response.choices[0].message.content, relevant_texts
    except Exception as e:
        return f"Error: {str(e)}", []


def format_sources(references):
    return "\n".join([f"å‚ç…§å…ƒ {i+1}:\n{ref}" for i, ref in enumerate(references)])


async def send_feedback_options():
    feedback_options = [
        cl.Action(name="like", label="ğŸ‘ è‰¯ã„", value='liked'),
        cl.Action(name="dislike", label="ğŸ‘ æ‚ªã„", value='disliked')
    ]
    await cl.Message(content="ã“ã®å›ç­”ã¯å½¹ã«ç«‹ã¡ã¾ã—ãŸã‹ï¼Ÿ", actions=feedback_options).send()


@cl.on_message
async def main(message: cl.Message):
    global file_content, vector_store, last_user_message

    user_message = message.content.strip()
    last_user_message = user_message

    if user_message.lower() == "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰":
        files = None
        while files is None:
            files = await cl.AskFileMessage(
                max_size_mb=20,
                content="PDFã€Excelã€ã¾ãŸã¯Wordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
                accept=[
                    "application/pdf",
                    "application/vnd.ms-excel",
                    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    "application/msword",
                    "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                ],
                raise_on_timeout=False,
            ).send()
        file = files[0]
        file_path = file.path
        file_extension = os.path.splitext(file_path)[1].lower()

        if file_extension == ".pdf":
            loader = PyMuPDFLoader(file_path)
        elif file_extension in [".xls", ".xlsx"]:
            loader = UnstructuredExcelLoader(file_path)
        elif file_extension in [".doc", ".docx"]:
            loader = UnstructuredWordDocumentLoader(file_path)
        else:
            await cl.Message(content="å¯¾å¿œã—ã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™ã€‚PDFã€Excelã€Wordã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚").send()
            return

        documents = loader.load()
        sanitized_docs = []
        sanitized_texts = []
        for doc in documents:
            clean_text = sanitize_text(doc.page_content)
            sanitized_texts.append(clean_text)
            sanitized_docs.append(type(doc)(page_content=clean_text, metadata=doc.metadata))

        vector_store = vectorize_documents(sanitized_docs)
        file_content = "\n".join(sanitized_texts)
        await cl.Message(content="ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸã€‚è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚").send()
    elif file_content:
        relevant_texts = search_documents(user_message, vector_store)
        tool_response, references = await call_openai_api(user_message, relevant_texts)
        await cl.Message(content=f"å›ç­”:\n{tool_response}").send()
        await cl.Message(content=f"ä»¥ä¸‹ã®å‚ç…§å…ƒã‚’ç¢ºèªã§ãã¾ã™ï¼š\n{format_sources(references)}").send()
        await send_feedback_options()
    else:
        await cl.Message(content="å…ˆã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚").send()


@cl.action_callback("source_0")
async def show_source_0(action: cl.Action):
    await cl.Message(content=f"å‚ç…§å…ƒ 1 ã®å†…å®¹:\n{action.value}").send()


@cl.action_callback("source_1")
async def show_source_1(action: cl.Action):
    await cl.Message(content=f"å‚ç…§å…ƒ 2 ã®å†…å®¹:\n{action.value}").send()


@cl.action_callback("source_2")
async def show_source_2(action: cl.Action):
    await cl.Message(content=f"å‚ç…§å…ƒ 3 ã®å†…å®¹:\n{action.value}").send()


@cl.action_callback("like")
async def like_feedback(action: cl.Action):
    await cl.Message(content="ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’ã‚ã‚ŠãŒã¨ã†ï¼").send()


@cl.action_callback("dislike")
async def dislike_feedback(action: cl.Action):
    global file_content, vector_store, last_user_message
    tool_response, references = await call_openai_api(last_user_message, [file_content])
    await cl.Message(content=f"å†ç”Ÿæˆã•ã‚ŒãŸå›ç­”:\n{tool_response}").send()
    await cl.Message(content=f"ä»¥ä¸‹ã®å‚ç…§å…ƒã‚’ç¢ºèªã§ãã¾ã™ï¼š\n{format_sources(references)}").send()
    await send_feedback_options()
